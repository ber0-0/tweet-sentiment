{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f14f087215</td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1915bebcb3</td>\n",
       "      <td>headache  wanna see my Julie</td>\n",
       "      <td>headache</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ab82634d5</td>\n",
       "      <td>had an awsome salad! I recommend getting the S...</td>\n",
       "      <td>had an awsome salad!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a5a1c996c0</td>\n",
       "      <td>fine! Going to do my big walk today 20 or so ...</td>\n",
       "      <td>fine!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a182b2638e</td>\n",
       "      <td>Thank a yoou  how are you? #TwitterTakeover</td>\n",
       "      <td>Thank</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1dcb6fdb13</td>\n",
       "      <td>Why don't adobe realise no one WANTS to pay fo...</td>\n",
       "      <td>Why don't adobe realise no one WANTS to pay fo...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6bff31375d</td>\n",
       "      <td>PRD take a long time to review!</td>\n",
       "      <td>PRD take a long time to review!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>e1ed43bebe</td>\n",
       "      <td>_2008 Well, having to revise them!  Was to do ...</td>\n",
       "      <td>2008 Well, having to revise them!  Was to do s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41fd07f670</td>\n",
       "      <td>Miss you my dear</td>\n",
       "      <td>Miss you my dear</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bc0f2cb758</td>\n",
       "      <td>Have just bought a TV tuner for my laptop.  He...</td>\n",
       "      <td>Have just bought a TV tuner for my laptop.  He...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0e6fb9153c</td>\n",
       "      <td>ya mine too but for very different reason</td>\n",
       "      <td>ya mine too but for very different reason</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49c7c9c6e2</td>\n",
       "      <td>Today Dan bought me Bio Dome AND the Reality B...</td>\n",
       "      <td>, my tummy is not happy. Boo.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>e6f5e9817d</td>\n",
       "      <td>oo noo thats not good</td>\n",
       "      <td>s not good</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fee2d997a9</td>\n",
       "      <td>misses her phone... having no service sucks</td>\n",
       "      <td>having no service sucks</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>459fc2a7c8</td>\n",
       "      <td>so i have like no more friends it's kinda sad</td>\n",
       "      <td>no more friends</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1a760553fc</td>\n",
       "      <td>i have perused the #fieldnotes website and it ...</td>\n",
       "      <td>i have perused the #fieldnotes website and it ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1e857fecf5</td>\n",
       "      <td>....welcome to public transport  X</td>\n",
       "      <td>....welcome to public transport  X</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22adf200c3</td>\n",
       "      <td>Also I popped the phone open and got all that ...</td>\n",
       "      <td>goddamn</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bae5414377</td>\n",
       "      <td>uh oh</td>\n",
       "      <td>uh oh</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22744e80f7</td>\n",
       "      <td>12:46AM. HAppy birthday little sister of mine....</td>\n",
       "      <td>HAppy birthday little sister of mine.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>e487233140</td>\n",
       "      <td>aaawww  no worries fresh start to work on gro...</td>\n",
       "      <td>aaawww  no worries</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22e66a73af</td>\n",
       "      <td>oh, /me still hasn't got around to starting it</td>\n",
       "      <td>oh, /me still hasn't got around to starting it</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>01cfa3807e</td>\n",
       "      <td>is sooo tired and too busy to tweet  im glad t...</td>\n",
       "      <td>glad</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7f59b000cd</td>\n",
       "      <td>what's going on ?</td>\n",
       "      <td>what's going on</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>127b2ac78c</td>\n",
       "      <td>I can't, I'm studying so I don't fail  Come o...</td>\n",
       "      <td>I can't, I'm studying so I don't fail  Come ov...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a6c77ff610</td>\n",
       "      <td>Just watched &amp;quot;Marley &amp;amp; Me.&amp;quot; Cute...</td>\n",
       "      <td>mp; Me</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>436b24fc93</td>\n",
       "      <td>not sure... there are fanciful expensive ones...</td>\n",
       "      <td>not sure... there are fanciful expensive ones ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>c63298701b</td>\n",
       "      <td>hello thereeeeeee</td>\n",
       "      <td>hello thereeeeeee</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4ce78f6e92</td>\n",
       "      <td>oh he is so cute... is he in uniteddogs.com? ...</td>\n",
       "      <td>cute.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2838f92a2b</td>\n",
       "      <td>has just joined the twitter community</td>\n",
       "      <td>has just joined the twitter community</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9dd2edd0fd</td>\n",
       "      <td>i'm actually starting to quite like lily allen...</td>\n",
       "      <td>o quite like lily allen and her music, to be h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>d86eaa0487</td>\n",
       "      <td>what Brody how dare u</td>\n",
       "      <td>what Brody how dare u</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2756df3899</td>\n",
       "      <td>I feel useless I don't know what to do right n...</td>\n",
       "      <td>useless</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>daadcab8af</td>\n",
       "      <td>I'm sooo HAPPY Demi's back on twitter!</td>\n",
       "      <td>I'm sooo HAPPY De</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2334cae701</td>\n",
       "      <td>kate is leaving me all by my lonesome</td>\n",
       "      <td>lonesome</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>89fc963188</td>\n",
       "      <td>I was rooting for Betty.</td>\n",
       "      <td>I was rooting for Betty.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "0   a3d0a7d5ad  Spent the entire morning in a meeting w/ a ven...   \n",
       "1   251b6a6766      Oh! Good idea about putting them on ice cream   \n",
       "2   c9e8d1ef1c  says good (or should i say bad?) afternoon!  h...   \n",
       "3   f14f087215         i dont think you can vote anymore! i tried   \n",
       "4   bf7473b12d             haha better drunken tweeting you mean?   \n",
       "5   1915bebcb3                       headache  wanna see my Julie   \n",
       "6   2ab82634d5  had an awsome salad! I recommend getting the S...   \n",
       "7   a5a1c996c0   fine! Going to do my big walk today 20 or so ...   \n",
       "8   a182b2638e        Thank a yoou  how are you? #TwitterTakeover   \n",
       "9   1dcb6fdb13  Why don't adobe realise no one WANTS to pay fo...   \n",
       "10  6bff31375d                    PRD take a long time to review!   \n",
       "11  e1ed43bebe  _2008 Well, having to revise them!  Was to do ...   \n",
       "12  41fd07f670                                   Miss you my dear   \n",
       "13  bc0f2cb758  Have just bought a TV tuner for my laptop.  He...   \n",
       "14  0e6fb9153c          ya mine too but for very different reason   \n",
       "15  49c7c9c6e2  Today Dan bought me Bio Dome AND the Reality B...   \n",
       "16  e6f5e9817d                              oo noo thats not good   \n",
       "17  fee2d997a9        misses her phone... having no service sucks   \n",
       "18  459fc2a7c8      so i have like no more friends it's kinda sad   \n",
       "19  1a760553fc  i have perused the #fieldnotes website and it ...   \n",
       "20  1e857fecf5                 ....welcome to public transport  X   \n",
       "21  22adf200c3  Also I popped the phone open and got all that ...   \n",
       "22  bae5414377                                              uh oh   \n",
       "23  22744e80f7  12:46AM. HAppy birthday little sister of mine....   \n",
       "24  e487233140   aaawww  no worries fresh start to work on gro...   \n",
       "25  22e66a73af     oh, /me still hasn't got around to starting it   \n",
       "26  01cfa3807e  is sooo tired and too busy to tweet  im glad t...   \n",
       "27  7f59b000cd                                  what's going on ?   \n",
       "28  127b2ac78c   I can't, I'm studying so I don't fail  Come o...   \n",
       "29  a6c77ff610  Just watched &quot;Marley &amp; Me.&quot; Cute...   \n",
       "30  436b24fc93   not sure... there are fanciful expensive ones...   \n",
       "31  c63298701b                                  hello thereeeeeee   \n",
       "32  4ce78f6e92   oh he is so cute... is he in uniteddogs.com? ...   \n",
       "33  2838f92a2b              has just joined the twitter community   \n",
       "34  9dd2edd0fd  i'm actually starting to quite like lily allen...   \n",
       "35  d86eaa0487                              what Brody how dare u   \n",
       "36  2756df3899  I feel useless I don't know what to do right n...   \n",
       "37  daadcab8af             I'm sooo HAPPY Demi's back on twitter!   \n",
       "38  2334cae701              kate is leaving me all by my lonesome   \n",
       "39  89fc963188                           I was rooting for Betty.   \n",
       "\n",
       "                                        selected_text sentiment  \n",
       "0         my boss was not happy w/ them. Lots of fun.   neutral  \n",
       "1                                                Good  positive  \n",
       "2         says good (or should i say bad?) afternoon!   neutral  \n",
       "3                  i dont think you can vote anymore!  negative  \n",
       "4                                              better  positive  \n",
       "5                                            headache  negative  \n",
       "6                                had an awsome salad!  positive  \n",
       "7                                               fine!  positive  \n",
       "8                                               Thank  positive  \n",
       "9   Why don't adobe realise no one WANTS to pay fo...   neutral  \n",
       "10                    PRD take a long time to review!   neutral  \n",
       "11  2008 Well, having to revise them!  Was to do s...   neutral  \n",
       "12                                   Miss you my dear  negative  \n",
       "13  Have just bought a TV tuner for my laptop.  He...  positive  \n",
       "14          ya mine too but for very different reason   neutral  \n",
       "15                      , my tummy is not happy. Boo.  negative  \n",
       "16                                         s not good  negative  \n",
       "17                            having no service sucks  negative  \n",
       "18                                    no more friends  negative  \n",
       "19  i have perused the #fieldnotes website and it ...   neutral  \n",
       "20                 ....welcome to public transport  X   neutral  \n",
       "21                                            goddamn  negative  \n",
       "22                                              uh oh  negative  \n",
       "23              HAppy birthday little sister of mine.  positive  \n",
       "24                                 aaawww  no worries  positive  \n",
       "25     oh, /me still hasn't got around to starting it   neutral  \n",
       "26                                               glad  positive  \n",
       "27                                    what's going on   neutral  \n",
       "28  I can't, I'm studying so I don't fail  Come ov...   neutral  \n",
       "29                                             mp; Me  positive  \n",
       "30  not sure... there are fanciful expensive ones ...   neutral  \n",
       "31                                  hello thereeeeeee   neutral  \n",
       "32                                              cute.  positive  \n",
       "33              has just joined the twitter community   neutral  \n",
       "34  o quite like lily allen and her music, to be h...  positive  \n",
       "35                              what Brody how dare u  negative  \n",
       "36                                            useless  negative  \n",
       "37                                  I'm sooo HAPPY De  positive  \n",
       "38                                           lonesome  negative  \n",
       "39                           I was rooting for Betty.   neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27486, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][2].replace('[^a-zA-Z#]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df['text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['says',\n",
       " 'good',\n",
       " '(',\n",
       " 'or',\n",
       " 'should',\n",
       " 'i',\n",
       " 'say',\n",
       " 'bad',\n",
       " '?',\n",
       " ')',\n",
       " 'afternoon',\n",
       " '!',\n",
       " ' ',\n",
       " 'http://plurk.com/p/wxpdj']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>says</td>\n",
       "      <td>say</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-LRB-</td>\n",
       "      <td>punct</td>\n",
       "      <td>(</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>or</td>\n",
       "      <td>or</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "      <td>VERB</td>\n",
       "      <td>MD</td>\n",
       "      <td>aux</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>acomp</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>?</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>punct</td>\n",
       "      <td>)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>!</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>http://plurk.com/p/wxpdj</td>\n",
       "      <td>http://plurk.com/p/wxpdj</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx://xxxx.xxx/x/xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Text                     Lemma    POS    TAG    DEP  \\\n",
       "0                       says                       say   VERB    VBZ   ROOT   \n",
       "1                       good                      good    ADJ     JJ  nsubj   \n",
       "2                          (                         (  PUNCT  -LRB-  punct   \n",
       "3                         or                        or  CCONJ     CC     cc   \n",
       "4                     should                    should   VERB     MD    aux   \n",
       "5                          i                         i   PRON    PRP  nsubj   \n",
       "6                        say                       say   VERB     VB   ROOT   \n",
       "7                        bad                       bad    ADJ     JJ  acomp   \n",
       "8                          ?                         ?  PUNCT      .  punct   \n",
       "9                          )                         )  PUNCT  -RRB-  punct   \n",
       "10                 afternoon                 afternoon   NOUN     NN   ROOT   \n",
       "11                         !                         !  PUNCT      .  punct   \n",
       "12                                                      SPACE    _SP          \n",
       "13  http://plurk.com/p/wxpdj  http://plurk.com/p/wxpdj    NUM     CD   ROOT   \n",
       "\n",
       "                     Shape  Alpha   Stop  \n",
       "0                     xxxx   True  False  \n",
       "1                     xxxx   True  False  \n",
       "2                        (  False  False  \n",
       "3                       xx   True   True  \n",
       "4                     xxxx   True   True  \n",
       "5                        x   True   True  \n",
       "6                      xxx   True   True  \n",
       "7                      xxx   True  False  \n",
       "8                        ?  False  False  \n",
       "9                        )  False  False  \n",
       "10                    xxxx   True  False  \n",
       "11                       !  False  False  \n",
       "12                          False  False  \n",
       "13  xxxx://xxxx.xxx/x/xxxx  False  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_table = []\n",
    "for token in doc:\n",
    "    token_table.append({'Text':token.text, \n",
    "                       'Lemma':token.lemma_,\n",
    "                       'POS':token.pos_, \n",
    "                       'TAG':token.tag_, \n",
    "                       'DEP':token.dep_,\n",
    "                       'Shape':token.shape_, \n",
    "                       'Alpha':token.is_alpha, \n",
    "                       'Stop':token.is_stop})\n",
    "display(pd.DataFrame(token_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].replace({'positive':1, 'neutral':0, 'negative':-1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    11118\n",
       " 1     8582\n",
       "-1     7786\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             1\n",
       "selected_text    1\n",
       "sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13133</th>\n",
       "      <td>fdb77c3752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID text selected_text  sentiment\n",
       "13133  fdb77c3752  NaN           NaN          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             0\n",
       "selected_text    0\n",
       "sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Spent the entire morning in a meeting w/ a ven...   \n",
       "1      Oh! Good idea about putting them on ice cream   \n",
       "2  says good (or should i say bad?) afternoon!  h...   \n",
       "3         i dont think you can vote anymore! i tried   \n",
       "4             haha better drunken tweeting you mean?   \n",
       "\n",
       "                                 selected_text  sentiment  \n",
       "0  my boss was not happy w/ them. Lots of fun.          0  \n",
       "1                                         Good          1  \n",
       "2  says good (or should i say bad?) afternoon!          0  \n",
       "3           i dont think you can vote anymore!         -1  \n",
       "4                                       better          1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(['textID'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'says good (or should i say bad?) afternoon!  http://plurk.com/p/wxpdj'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = nlp.create_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentencizer before parser in nlp pipeline\n",
    "nlp.add_pipe(sent, before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them.\n",
      "Lots of fun.\n",
      " I had other plans for my morning\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_data_cleaning(text):\n",
    "    #text = text.str.replace('[^a-zA-Z#]', ' ')\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NUM\": #remove numbers and urls\n",
    "            temp = ''\n",
    "        elif token.lemma_ != \"-PRON-\": #remove prounouns and change words to lower case\n",
    "            temp = token.lemma_.lower().strip()\n",
    "        else:\n",
    "            temp = token.lower_ #change words to lower case\n",
    "        tokens.append(temp)\n",
    "    \n",
    "    tokens = [re.sub(r'[^a-zA-Z#]', ' ', file) for file in tokens] #replace special characters to whitespace\n",
    "    \n",
    "    tokens = [re.sub(r'\\s', '', file) for file in tokens] #remove whitespaces\n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords and token not in punct: #remove stop words and punctuations\n",
    "            cleaned_tokens.append(token)\n",
    "    \n",
    "    long_tokens = []\n",
    "    for token in cleaned_tokens: #remove words with length shorter than 3\n",
    "        if len(token) >= 3:\n",
    "            long_tokens.append(token)\n",
    "    \n",
    "    return long_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ....welcome to public transport  X'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['welcome', 'public', 'transport']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_cleaning(data['text'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_text = tfidf.fit_transform(data['text'][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(token_text[0].T.todense(), index=tfidf.get_feature_names(), columns=[\"tfidf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_dt = tfidf.fit(X_train)\n",
    "#token_dt = tfidf.transform(X_train)\n",
    "#tok_data = pd.DataFrame(columns=tokenized_dt.get_feature_names(), data=token_dt.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_dt.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tok_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21988,), (5497,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipe = Pipeline([('tfidf', tfidf), ('LinearSVC', svc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function text_data_cleaning at 0x109b17048>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('LinearSVC',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6623612879752593"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svc_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.62      0.64      1543\n",
      "           0       0.63      0.66      0.65      2259\n",
      "           1       0.71      0.70      0.70      1695\n",
      "\n",
      "    accuracy                           0.66      5497\n",
      "   macro avg       0.67      0.66      0.66      5497\n",
      "weighted avg       0.66      0.66      0.66      5497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 962,  489,   92],\n",
       "       [ 376, 1499,  384],\n",
       "       [ 118,  397, 1180]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = Pipeline([('tfidf', tfidf), ('XGB', xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=100, n_jobs=1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.42      0.54      1543\n",
      "           0       0.56      0.85      0.68      2259\n",
      "           1       0.78      0.58      0.67      1695\n",
      "\n",
      "    accuracy                           0.65      5497\n",
      "   macro avg       0.71      0.62      0.63      5497\n",
      "weighted avg       0.69      0.65      0.64      5497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 642,  823,   78],\n",
       "       [ 142, 1919,  198],\n",
       "       [  44,  662,  989]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
